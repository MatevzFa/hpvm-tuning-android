{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import scipy as sc\n",
                "import matplotlib.pyplot as plt"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/home/matevz/.pyenv/versions/3.6.13/envs/hpvm/lib/python3.6/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
                        "  warnings.warn(msg)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "labels = [\n",
                "    \"Walking\",\n",
                "    \"W. Upstairs\",\n",
                "    \"W. Downstairs\",\n",
                "    \"Sitting\",\n",
                "    \"Standing\",\n",
                "    \"Lying\",\n",
                "]\n",
                "\n",
                "segments = []\n",
                "with open(\"model_log\") as f:\n",
                "    lines_raw = [l.strip() for l in f.readlines()]\n",
                "    new_segment = None\n",
                "    for l in lines_raw:\n",
                "        if l == \"begin\":\n",
                "            new_segment = []\n",
                "        elif l == \"end\":\n",
                "            segments.append(new_segment)\n",
                "            new_segment = None\n",
                "        else:\n",
                "            new_segment.append(l)\n",
                "\n",
                "df = pd.DataFrame(\n",
                "    [s.split() for seg in segments for s in seg],\n",
                "    columns=[\"conf\", \"true\", \"pred\", 0, 1, 2, 3, 4, 5],\n",
                ").astype({\n",
                "    \"conf\": \"str\",\n",
                "    \"true\": \"int\",\n",
                "    \"pred\": \"int\",\n",
                "    0: \"float\", 1: \"float\", 2: \"float\", 3: \"float\", 4: \"float\", 5: \"float\",\n",
                "})\n",
                "del segments\n",
                "\n",
                "sm_c = df.loc[:, [0, 1, 2, 3, 4, 5]]\n",
                "df[\"min\"] = sm_c.min(axis=1)\n",
                "df[\"max\"] = sm_c.max(axis=1)\n",
                "\n",
                "\n",
                "def max_2_difference(row: pd.Series):\n",
                "    max2 = row.nlargest(2).values\n",
                "    return max2[0] - max2[1]\n",
                "\n",
                "\n",
                "df[\"max-max2\"] = sm_c.apply(max_2_difference, axis=1, result_type='expand')\n",
                "df[\"var\"] = sm_c.var(axis=1)\n",
                "df[\"max-min\"] = df[\"max\"]-df[\"min\"]\n",
                "df[\"correct\"] = (df[\"true\"] == df[\"pred\"]).astype(int)\n",
                "\n",
                "accuracies = df.groupby([\"conf\", \"true\"]).agg({'correct': 'sum', 'pred': 'count'})\n",
                "accuracies[\"acc\"] = accuracies[\"correct\"] / accuracies[\"pred\"]\n",
                "\n",
                "accuracies_pred = df.groupby([\"conf\", \"pred\"]).agg({'correct': 'sum', 'true': 'count'})\n",
                "accuracies_pred[\"acc\"] = accuracies_pred[\"correct\"] / accuracies_pred[\"true\"]\n",
                "\n",
                "# print(\"before\")\n",
                "# print(df[\"correct\"].value_counts().sort_index())\n",
                "\n",
                "# print(\"after\")\n",
                "# original = df.copy()\n",
                "# for _ in range(5):\n",
                "#     df = df.append(original[original.correct == 0])\n",
                "# print(df[\"correct\"].value_counts().sort_index())"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "feats = [\"max\", \"max-max2\"]\n",
                "clz = \"correct\""
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def do():\n",
                "    from sklearn.model_selection import train_test_split, cross_validate\n",
                "    from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
                "    from sklearn.linear_model import LinearRegression\n",
                "    from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, roc_auc_score, plot_roc_curve, f1_score\n",
                "    from matplotlib.lines import Line2D\n",
                "\n",
                "    nlabels = len(df[\"true\"].unique())\n",
                "    nconfs = len(df[\"conf\"].unique())\n",
                "\n",
                "    fig, axs = plt.subplots(nrows=nconfs, ncols=nlabels, figsize=(6, 10), sharex=True, sharey=True)\n",
                "    for i, (conf, grpc) in enumerate(df.groupby([\"conf\"])):\n",
                "        for j, (label, grp) in enumerate(grpc.groupby([\"pred\"])):\n",
                "\n",
                "            ax = axs[i, label]\n",
                "\n",
                "            X, y = grp.loc[:, feats], grp.loc[:, clz]\n",
                "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "            acc = accuracies_pred.loc[conf].loc[label].acc\n",
                "\n",
                "            ax.set_ylim(-0.05, 1.05)\n",
                "            ax.hlines(acc, 0, 1, colors='r', linestyles='--')\n",
                "\n",
                "            classifier = GaussianNB()\n",
                "\n",
                "            classifier.fit(X_train, y_train)\n",
                "\n",
                "            y_pred = classifier.predict(X_test)\n",
                "\n",
                "            plot_kw = dict(c='b')\n",
                "\n",
                "            def text(s): return ax.text(0.5, 0.5, s, ha='center', va='center', fontsize='small')\n",
                "\n",
                "            if np.all(y_pred == 0):\n",
                "                # TPR = 0\n",
                "                # TNR = 1\n",
                "                ax.set_facecolor((0.9, 0.9, 0.9))\n",
                "                text(\"TPR=0\\nTNR=1\")\n",
                "            elif np.all(y_pred == 1):\n",
                "                # TPR = 1\n",
                "                # TNR = 0\n",
                "                ax.set_facecolor((0.9, 0.9, 0.9))\n",
                "                text(\"TPR=1\\nTNR=0\")\n",
                "            elif np.any(y_test == 0) and np.any(y_test == 1):\n",
                "                # else:\n",
                "                # dsp = plot_roc_curve(classifier, X_test, y_test, ax=ax, pos_label=1, name=f\"Predicting correct\")\n",
                "                dsp = plot_roc_curve(classifier, X_test, y_test, ax=ax, pos_label=0,\n",
                "                                    name=f\"Predicting incorrect\", **plot_kw)\n",
                "                ax.plot([0, 1], [0, 1], '--', c='gray')\n",
                "                ax.legend().remove()\n",
                "            else:\n",
                "                text(\"No data\")\n",
                "                ax.set_facecolor((0.9, 0.9, 0.9))\n",
                "\n",
                "            ax.set_ylabel(\"\")\n",
                "            ax.set_xlabel(\"\")\n",
                "\n",
                "            if label == len(labels)-1:\n",
                "                ax.text(1.2, 0.5, conf)\n",
                "\n",
                "            if i == 0:\n",
                "                ax.set_title(f\"{labels[label]}\", rotation=45, fontsize='small')\n",
                "\n",
                "    fig.text(0.5, 0.98, \"Predicted activity\", ha='center')  # x\n",
                "\n",
                "    fig.text(0.5, 0.07, \"True negative rate (TNR)\", ha='center')  # x\n",
                "    fig.text(0.04, 0.5, \"True positive rate (TPR)\", va='center', rotation='vertical')  # y\n",
                "\n",
                "    legend_elements = [Line2D([0], [0], c='b', ls='-', label='ROC curve'),\n",
                "                    Line2D([0], [0], c='r', ls='--', label='HAR model accuracy'), ]\n",
                "    fig.legend(handles=legend_elements, ncol=2, loc='center', bbox_to_anchor=(0, 0.03, 1, 0))\n",
                "\n",
                "\n",
                "    plt.savefig(\"roc-confidence-bayes.pdf\", bbox_inches='tight')\n",
                "    plt.show()\n",
                "\n",
                "do()\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "def do():\n",
                "    from sklearn.model_selection import train_test_split, cross_validate\n",
                "    from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
                "    from sklearn.linear_model import LinearRegression\n",
                "    from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, roc_auc_score, plot_roc_curve, f1_score, make_scorer, precision_score, recall_score\n",
                "    from matplotlib.lines import Line2D\n",
                "    from sys import stderr\n",
                "    from collections import Counter\n",
                "\n",
                "    nlabels = len(df[\"true\"].unique())\n",
                "    nconfs = len(df[\"conf\"].unique())\n",
                "\n",
                "    score_grid_p = np.zeros((nconfs, nlabels))\n",
                "    score_grid_r = np.zeros((nconfs, nlabels))\n",
                "    score_grid_har = np.zeros((nconfs, nlabels))\n",
                "\n",
                "    def for_pos_label(pos_label):\n",
                "        precision_scorer = make_scorer(precision_score, pos_label=pos_label, zero_division=0)\n",
                "        recall_scorer = make_scorer(recall_score, pos_label=pos_label, zero_division=0)\n",
                "\n",
                "        for i, (conf, grpc) in enumerate(df.groupby([\"conf\"])):\n",
                "            for j, (label, grp) in enumerate(grpc.groupby([\"pred\"])):\n",
                "\n",
                "                X, y = grp.loc[:, feats], grp.loc[:, clz]\n",
                "\n",
                "                score_grid_har[i, j] = accuracies_pred.loc[conf].loc[label].acc\n",
                "\n",
                "                cv=3\n",
                "\n",
                "                counts = Counter(y)\n",
                "                if counts[0] <= cv or counts[1] <= cv:\n",
                "                    score_grid_p[i, j] = np.nan\n",
                "                    score_grid_r[i, j] = np.nan\n",
                "                    continue\n",
                "\n",
                "                classifier = GaussianNB()\n",
                "\n",
                "                scores = cross_validate(classifier, X, y, scoring={\n",
                "                                        'p': precision_scorer, 'r': recall_scorer},cv=cv)\n",
                "\n",
                "                score_grid_p[i, j] = scores[\"test_p\"].mean()\n",
                "                score_grid_r[i, j] = scores[\"test_r\"].mean()\n",
                "\n",
                "        f1_avg = 2*(score_grid_p*score_grid_r)/(score_grid_p+score_grid_r)\n",
                "\n",
                "        fig, axs = plt.subplots(1, 4, sharey=True)\n",
                "\n",
                "        plt.setp(axs,\n",
                "                xticks=np.arange(nlabels), xticklabels=[l.replace(\"\\n\", \" \") for l in labels],\n",
                "                yticks=np.arange(nconfs))\n",
                "\n",
                "        for ax in axs:\n",
                "            plt.setp(ax.get_xticklabels(), rotation='vertical')\n",
                "\n",
                "        cmap = \"viridis\"\n",
                "\n",
                "        axs[0].set_title(\"Precision\")\n",
                "        axs[0].imshow(score_grid_p, vmin=0, vmax=1, cmap=cmap)\n",
                "\n",
                "        axs[1].set_title(\"Recall\")\n",
                "        axs[1].imshow(score_grid_r, vmin=0, vmax=1, cmap=cmap)\n",
                "\n",
                "        axs[2].set_title(\"F1\")\n",
                "        axs[2].imshow(f1_avg, vmin=0, vmax=1, cmap=cmap)\n",
                "\n",
                "        axs[3].set_title(\"Baseline F1\\nRecall=1\")\n",
                "        baseline = (1-score_grid_har) if pos_label == 0 else score_grid_har\n",
                "        im = axs[3].imshow(baseline, vmin=0, vmax=1, cmap=cmap)\n",
                "\n",
                "\n",
                "\n",
                "        (_, y0, _, hig) = axs[2].get_position().bounds\n",
                "\n",
                "        # fig.subplots_adjust(right=0.8)\n",
                "        # put colorbar at desire position\n",
                "        cbar_ax = fig.add_axes([0.95, y0, 0.02, hig])\n",
                "        fig.colorbar(im, cax=cbar_ax)\n",
                "\n",
                "        fig.text(0.5, -0.14, 'Predicted activity', ha='center')\n",
                "        fig.text(0.04, 0.5, 'Configuration index', va='center', rotation='vertical')\n",
                "        # fig.suptitle(f\"Correctness prediction for class: {'correct' if pos_label else 'wrong'}\")\n",
                "\n",
                "        plt.savefig(f\"grid-confidence-bayes-{pos_label}.pdf\", bbox_inches='tight')\n",
                "        plt.show()\n",
                "    for_pos_label(0)\n",
                "    for_pos_label(1)\n",
                "    \n",
                "\n",
                "do()\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def do():\n",
                "    from sklearn.model_selection import train_test_split, cross_validate\n",
                "    from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
                "    from sklearn.linear_model import LinearRegression\n",
                "    from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, roc_auc_score, plot_roc_curve, f1_score, make_scorer, precision_score, recall_score\n",
                "    from matplotlib.lines import Line2D\n",
                "    from sys import stderr\n",
                "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
                "\n",
                "    nlabels = len(df[\"true\"].unique())\n",
                "    nconfs = len(df[\"conf\"].unique())\n",
                "\n",
                "    score_grid_acc = np.zeros((nlabels, nconfs))\n",
                "    score_grid_qos = np.zeros((nlabels, nconfs))\n",
                "\n",
                "    for i, (conf, grpc) in enumerate(df.groupby([\"conf\"])):\n",
                "        for j, (label, grp) in enumerate(grpc.groupby([\"true\"])):\n",
                "            acc = accuracies.loc[conf].loc[label].acc\n",
                "\n",
                "            score_grid_acc[j, i] = acc\n",
                "            score_grid_qos[j, i] = max(accuracies.loc[\"conf0\"].loc[label].acc - acc, 0)\n",
                "\n",
                "    fig, axs = plt.subplots(1, 2, figsize=(8,4),sharey=True)\n",
                "\n",
                "    plt.setp(axs,\n",
                "             yticks=np.arange(nlabels), yticklabels=[l.replace(\"\\n\", \" \") for l in labels],\n",
                "             xticks=np.arange(nconfs), xticklabels=np.arange(nconfs))\n",
                "\n",
                "    # for ax in axs:\n",
                "    #     plt.setp(ax.get_xticklabels(), rotation='vertical')\n",
                "\n",
                "    axs[0].set_title(\"Accuracy\")\n",
                "    axs[0].set_xlabel(\"Configuration index\")\n",
                "    im0 = axs[0].imshow(score_grid_acc, vmin=0, vmax=1, cmap=\"Blues_r\")\n",
                "    divider0 = make_axes_locatable(axs[0])\n",
                "    cax0 = divider0.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
                "    fig.colorbar(im0, cax=cax0)\n",
                "\n",
                "    axs[1].set_title(\"QoS loss\")\n",
                "    axs[1].set_xlabel(\"Configuration index\")\n",
                "    im1 = axs[1].imshow(score_grid_qos, cmap=\"Greens\")\n",
                "    divider1 = make_axes_locatable(axs[1])\n",
                "    cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
                "    fig.colorbar(im1, cax=cax1)\n",
                "\n",
                "    plt.savefig(\"grid-accuracy-and-qos.pdf\", bbox_inches='tight')\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "do()\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.6.13",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6.13 64-bit ('hpvm': pyenv)"
        },
        "interpreter": {
            "hash": "5bcd1cd6c9700bc958d3c9a5ea0d6cc5f88c32efd4faefe37b8bdf3d5909c3fa"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}